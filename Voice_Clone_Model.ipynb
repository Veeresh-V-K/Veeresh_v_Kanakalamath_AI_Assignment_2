{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gtts\n",
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7lHhMgcrq9i",
        "outputId": "c786895a-06f9-4b65-d0ae-bd9ab7aa2087"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gtts in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.27.1)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.4)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeCEBIyXmIlN",
        "outputId": "3eeb3d9d-51c1-409e-ffa9-e06566318e6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-51f3456c9fb9>:30: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  audio = audio / np.max(audio)\n",
            "<ipython-input-2-51f3456c9fb9>:30: RuntimeWarning: invalid value encountered in true_divide\n",
            "  audio = audio / np.max(audio)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of audio files: 4857\n",
            "Epoch 1/5\n",
            "152/152 [==============================] - 33s 202ms/step - loss: nan\n",
            "Epoch 2/5\n",
            "152/152 [==============================] - 32s 213ms/step - loss: nan\n",
            "Epoch 3/5\n",
            "152/152 [==============================] - 31s 201ms/step - loss: nan\n",
            "Epoch 4/5\n",
            "152/152 [==============================] - 31s 202ms/step - loss: nan\n",
            "Epoch 5/5\n",
            "152/152 [==============================] - 31s 204ms/step - loss: nan\n",
            "1/1 [==============================] - 0s 436ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-51f3456c9fb9>:77: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  generated_audio = np.int16(generated_audio * (32767 / np.max(np.abs(generated_audio))))\n",
            "<ipython-input-2-51f3456c9fb9>:77: RuntimeWarning: invalid value encountered in multiply\n",
            "  generated_audio = np.int16(generated_audio * (32767 / np.max(np.abs(generated_audio))))\n"
          ]
        }
      ],
      "source": [
        "import soundfile as sf\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import librosa\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the path to the VoxCeleb-1 dataset ZIP file in Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/Colab Notebooks/VoxCeleb-1 dataset.zip'\n",
        "\n",
        "# Extract the dataset ZIP file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('voxceleb-1-dataset')\n",
        "\n",
        "# Preprocess audio files\n",
        "audio_files = []\n",
        "for root, _, files in os.walk('voxceleb-1-dataset'):\n",
        "    for file in files:\n",
        "        if file.endswith('.wav'):\n",
        "            audio_file = os.path.join(root, file)\n",
        "            audio, sr = librosa.load(audio_file, sr=None)\n",
        "            audio = librosa.amplitude_to_db(audio)\n",
        "            audio = audio / np.max(audio)\n",
        "            target_length = 8000\n",
        "            if len(audio) < target_length:\n",
        "                padding = np.zeros(target_length - len(audio))\n",
        "                audio = np.concatenate((audio, padding))\n",
        "            elif len(audio) > target_length:\n",
        "                audio = audio[:target_length]\n",
        "            audio = audio.reshape((1, 8000))\n",
        "            audio_files.append(audio)\n",
        "print(f\"Number of audio files: {len(audio_files)}\")\n",
        "\n",
        "# Train the model\n",
        "audio_data = np.concatenate(audio_files, axis=0)  # Concatenate audio files into a single array\n",
        "target_data = np.zeros_like(audio_data)  # Create a dummy target array\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(8000,)),\n",
        "    tf.keras.layers.Reshape((8000, 1)),  # Add Reshape layer for compatibility with LSTM\n",
        "    tf.keras.layers.LSTM(128),\n",
        "    tf.keras.layers.Dense(1, activation='linear')\n",
        "])\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "model.fit(audio_data, target_data, epochs=5)\n",
        "\n",
        "# Clean up the extracted files\n",
        "shutil.rmtree('voxceleb-1-dataset')\n",
        "\n",
        "# Generate speech from text\n",
        "text = 'This is a test of the voice cloning model.'\n",
        "tts = gTTS(text=text, lang='en')\n",
        "tts.save('/content/generated_speech.mp3')\n",
        "\n",
        "speech, _ = librosa.load('/content/generated_speech.mp3', sr=8000)\n",
        "speech = librosa.amplitude_to_db(speech)\n",
        "speech = speech / np.max(speech)\n",
        "if len(speech) < target_length:\n",
        "    padding = np.zeros(target_length - len(speech))\n",
        "    speech = np.concatenate((speech, padding))\n",
        "elif len(speech) > target_length:\n",
        "    speech = speech[:target_length]\n",
        "speech = speech.reshape((1, 8000))\n",
        "generated_audio = model.predict(speech)\n",
        "generated_audio = np.power(generated_audio, 10)\n",
        "generated_audio = librosa.db_to_amplitude(generated_audio)\n",
        "generated_audio = np.nan_to_num(generated_audio, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "generated_audio = librosa.resample(generated_audio, orig_sr=8000, target_sr=16000)\n",
        "\n",
        "# Save the generated speech audio\n",
        "generated_audio = np.int16(generated_audio * (32767 / np.max(np.abs(generated_audio))))\n",
        "audio_segment = AudioSegment(generated_audio.tobytes(), frame_rate=16000, sample_width=2, channels=1)\n",
        "audio_segment.export('/content/generated_speech_output.mp3', format='mp3')\n",
        "sf.write('/content/generated_speech.wav', generated_audio, 16000, format='WAV')\n"
      ]
    }
  ]
}